{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e70772b-2709-4ff3-bce4-c02af4c7a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b81a5d2-de16-4696-8ffe-86beaca7c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.add_dll_directory(r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\bin\")\n",
    "import ibatensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffe483f-77e0-46eb-9269-bc62140635de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tensor_info(label, tensor):\n",
    "    print(f\"{label} shape:\", tensor.shape)\n",
    "    s = tensor.to_string()\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54eaf0ea-3944-4716-b22f-f08bcf7557f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "0\t1\t2\t3\t4\t\n",
      "5\t6\t7\t8\t9\t\n",
      "10\t11\t12\t13\t14\t\n",
      "15\t16\t17\t18\t19\t\n",
      "20\t21\t22\t23\t24\t\n",
      "\n",
      "\n",
      "Kernel shape: [1, 1, 3, 3]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "1\t1\t1\t\n",
      "1\t1\t1\t\n",
      "1\t1\t1\t\n",
      "\n",
      "\n",
      "\n",
      "ğŸ§ª Testing conv2d\n",
      "Conv2D Output shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "12\t21\t27\t33\t24\t\n",
      "33\t54\t63\t72\t51\t\n",
      "63\t99\t108\t117\t81\t\n",
      "93\t144\t153\t162\t111\t\n",
      "72\t111\t117\t123\t84\t\n",
      "\n",
      "\n",
      "\n",
      "ğŸ§ª Testing ReLU\n",
      "ReLU Output shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "12\t21\t27\t33\t24\t\n",
      "33\t54\t63\t72\t51\t\n",
      "63\t99\t108\t117\t81\t\n",
      "93\t144\t153\t162\t111\t\n",
      "72\t111\t117\t123\t84\t\n",
      "\n",
      "\n",
      "\n",
      "ğŸ§ª Testing avg_pool\n",
      "Avg Pool Output shape: [1, 1, 2, 2]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "30\t48.75\t\n",
      "99.75\t135\t\n",
      "\n",
      "\n",
      "\n",
      "ğŸ§ª Testing max_pool\n",
      "max_pool shape: [1, 1, 2, 2]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "54\t72\t\n",
      "144\t162\t\n",
      "\n",
      "\n",
      "\n",
      "ğŸ” Testing backprop functions\n",
      "ğŸ”§ conv2d_backward_wr_kernel\n",
      "Grad Kernel shape: [1, 1, 3, 3]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "16632\t20616\t18123\t\n",
      "25068\t30444\t26316\t\n",
      "22374\t26898\t23028\t\n",
      "\n",
      "\n",
      "ğŸ”§ conv2d_backward_wr_input\n",
      "Grad Input shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "120\t210\t270\t270\t276\t\n",
      "282\t480\t594\t576\t567\t\n",
      "486\t810\t972\t918\t822\t\n",
      "582\t960\t1134\t1056\t843\t\n",
      "420\t690\t810\t750\t552\t\n",
      "\n",
      "\n",
      "ğŸ”§ max_pool_backward_wr_input\n",
      "Grad Max Pool shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "1935\t0\t0\t0\t0\t\n",
      "0\t12\t0\t21\t0\t\n",
      "0\t0\t0\t0\t0\t\n",
      "0\t27\t0\t33\t0\t\n",
      "0\t0\t0\t0\t0\t\n",
      "\n",
      "\n",
      "ğŸ”§ avg_pool_backward_wr_input\n",
      "Grad Avg Pool shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "3\t3\t5.25\t5.25\t0\t\n",
      "3\t3\t5.25\t5.25\t0\t\n",
      "8.25\t8.25\t13.5\t13.5\t0\t\n",
      "8.25\t8.25\t13.5\t13.5\t0\t\n",
      "0\t0\t0\t0\t0\t\n",
      "\n",
      "\n",
      "ğŸ”§ conv2d_backwards_bias_wr_sigma\n",
      "Grad Bias shape: [1, 1, 1, 1]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "2148\t\n",
      "\n",
      "\n",
      "ğŸ”§ relu_backwards\n",
      "Grad ReLU shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "12\t21\t27\t33\t24\t\n",
      "33\t54\t63\t72\t51\t\n",
      "63\t99\t108\t117\t81\t\n",
      "93\t144\t153\t162\t111\t\n",
      "72\t111\t117\t123\t84\t\n",
      "\n",
      "\n",
      "ğŸ”§ bias_backwards\n",
      "Bias Backward shape: [1, 1, 1, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "276\t432\t473.25\t512.25\t351\t\n",
      "\n",
      "\n",
      "\n",
      "âœ… All tests complete!\n"
     ]
    }
   ],
   "source": [
    "data = np.arange(25, dtype=np.float32).reshape(1, 1, 5, 5)\n",
    "input_tensor = ibatensor.Tensor(data, 1)\n",
    "print_tensor_info(\"Input Tensor\", input_tensor)\n",
    "\n",
    "# Create a 1x1x3x3 kernel (out_channels=1, in_channels=1, 3x3)\n",
    "kernel_data = np.ones((1, 1, 3, 3), dtype=np.float32)\n",
    "kernel_tensor = ibatensor.Tensor(kernel_data, 1)\n",
    "print_tensor_info(\"Kernel\", kernel_tensor)\n",
    "\n",
    "print(\"\\nğŸ§ª Testing conv2d\")\n",
    "conv_output = input_tensor.conv2d(kernel_tensor, padding=1, stride=1)\n",
    "print_tensor_info(\"Conv2D Output\", conv_output)\n",
    "\n",
    "print(\"\\nğŸ§ª Testing ReLU\")\n",
    "relu_out = conv_output.relu()\n",
    "print_tensor_info(\"ReLU Output\", relu_out)\n",
    "\n",
    "print(\"\\nğŸ§ª Testing avg_pool\")\n",
    "avg_pooled = conv_output.avg_pool(K=2, padding=0, stride=2)\n",
    "print_tensor_info(\"Avg Pool Output\", avg_pooled)\n",
    "\n",
    "print(\"\\nğŸ§ª Testing max_pool\")\n",
    "max_pool_result = conv_output.max_pool(K=2, padding=0, stride=2)\n",
    "print_tensor_info(\"max_pool\", max_pool_result.output)\n",
    "\n",
    "print(\"\\nğŸ” Testing backprop functions\")\n",
    "\n",
    "# Use conv_output as sigma\n",
    "sigma = conv_output\n",
    "\n",
    "print(\"ğŸ”§ conv2d_backward_wr_kernel\")\n",
    "grad_kernel = ibatensor.conv2d_backward_wr_kernel(input_tensor, sigma, kernel_tensor, padding=1, stride=1)\n",
    "print_tensor_info(\"Grad Kernel\", grad_kernel)\n",
    "\n",
    "print(\"ğŸ”§ conv2d_backward_wr_input\")\n",
    "grad_input = ibatensor.conv2d_backward_wr_input(input_tensor, sigma, kernel_tensor, padding=1, stride=1)\n",
    "print_tensor_info(\"Grad Input\", grad_input)\n",
    "\n",
    "print(\"ğŸ”§ max_pool_backward_wr_input\")\n",
    "grad_mp = ibatensor.max_pool_backward_wr_input(conv_output, sigma, max_pool_result.max_inds_ptr, K=2, padding=0, stride=2)\n",
    "print_tensor_info(\"Grad Max Pool\", grad_mp)\n",
    "\n",
    "print(\"ğŸ”§ avg_pool_backward_wr_input\")\n",
    "grad_avg = ibatensor.avg_pool_backward_wr_input(conv_output, sigma, K=2, padding=0, stride=2)\n",
    "print_tensor_info(\"Grad Avg Pool\", grad_avg)\n",
    "\n",
    "print(\"ğŸ”§ conv2d_backwards_bias_wr_sigma\")\n",
    "grad_bias = ibatensor.conv2d_backwards_bias_wr_sigma(sigma)\n",
    "print_tensor_info(\"Grad Bias\", grad_bias)\n",
    "\n",
    "print(\"ğŸ”§ relu_backwards\")\n",
    "grad_relu = ibatensor.relu_backwards(sigma, conv_output)\n",
    "print_tensor_info(\"Grad ReLU\", grad_relu)\n",
    "\n",
    "print(\"ğŸ”§ bias_backwards\")\n",
    "grad_b = ibatensor.bias_backwards(sigma)\n",
    "print_tensor_info(\"Bias Backward\", grad_b)\n",
    "\n",
    "print(\"\\nâœ… All tests complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af261f5e-414f-496c-8240-d0406c6b9029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a627b423-827f-4623-9ff4-7bc185f6672d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
