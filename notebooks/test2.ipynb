{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e70772b-2709-4ff3-bce4-c02af4c7a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b81a5d2-de16-4696-8ffe-86beaca7c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.add_dll_directory(r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.8\\bin\")\n",
    "import ibatensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ffe483f-77e0-46eb-9269-bc62140635de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tensor_info(label, tensor):\n",
    "    print(f\"{label} shape:\", tensor.shape)\n",
    "    s = tensor.to_string()\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54eaf0ea-3944-4716-b22f-f08bcf7557f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "0\t1\t2\t3\t4\t\n",
      "5\t6\t7\t8\t9\t\n",
      "10\t11\t12\t13\t14\t\n",
      "15\t16\t17\t18\t19\t\n",
      "20\t21\t22\t23\t24\t\n",
      "\n",
      "\n",
      "\n",
      " Testing softmax\n",
      "Softmax Output shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "0.0116562\t0.0316849\t0.0861285\t0.234122\t0.636409\t\n",
      "0.0116562\t0.0316849\t0.0861285\t0.234122\t0.636409\t\n",
      "0.0116562\t0.0316849\t0.0861285\t0.234122\t0.636409\t\n",
      "0.0116562\t0.0316849\t0.0861285\t0.234122\t0.636409\t\n",
      "0.0116562\t0.0316849\t0.0861285\t0.234122\t0.636409\t\n",
      "\n",
      "\n",
      "Kernel shape: [1, 1, 3, 3]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "1\t1\t1\t\n",
      "1\t1\t1\t\n",
      "1\t1\t1\t\n",
      "\n",
      "\n",
      "\n",
      "🧪 Testing conv2d\n",
      "Conv2D Output shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "12\t21\t27\t33\t24\t\n",
      "33\t54\t63\t72\t51\t\n",
      "63\t99\t108\t117\t81\t\n",
      "93\t144\t153\t162\t111\t\n",
      "72\t111\t117\t123\t84\t\n",
      "\n",
      "\n",
      "\n",
      "🧪 Testing ReLU\n",
      "ReLU Output shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "12\t21\t27\t33\t24\t\n",
      "33\t54\t63\t72\t51\t\n",
      "63\t99\t108\t117\t81\t\n",
      "93\t144\t153\t162\t111\t\n",
      "72\t111\t117\t123\t84\t\n",
      "\n",
      "\n",
      "\n",
      "🧪 Testing avg_pool\n",
      "Avg Pool Output shape: [1, 1, 2, 2]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "30\t48.75\t\n",
      "99.75\t135\t\n",
      "\n",
      "\n",
      "\n",
      "🧪 Testing max_pool\n",
      "max_pool shape: [1, 1, 2, 2]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "54\t72\t\n",
      "144\t162\t\n",
      "\n",
      "\n",
      "\n",
      "🔁 Testing backprop functions\n",
      "🔧 conv2d_backward_wr_kernel\n",
      "Grad Kernel shape: [1, 1, 3, 3]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "16620\t20595\t18096\t\n",
      "25035\t30420\t26283\t\n",
      "22320\t26835\t22956\t\n",
      "\n",
      "\n",
      "🔧 conv2d_backward_wr_input\n",
      "Grad Input shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "120\t210\t270\t270\t276\t\n",
      "282\t480\t594\t576\t567\t\n",
      "486\t810\t972\t918\t822\t\n",
      "582\t960\t1134\t1056\t843\t\n",
      "420\t690\t810\t750\t552\t\n",
      "\n",
      "\n",
      "🔧 max_pool_backward_wr_input\n",
      "Grad Max Pool shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "1935\t0\t0\t0\t0\t\n",
      "0\t12\t0\t21\t0\t\n",
      "0\t0\t0\t0\t0\t\n",
      "0\t27\t0\t33\t0\t\n",
      "0\t0\t0\t0\t0\t\n",
      "\n",
      "\n",
      "🔧 avg_pool_backward_wr_input\n",
      "Grad Avg Pool shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "3\t3\t5.25\t5.25\t0\t\n",
      "3\t3\t5.25\t5.25\t0\t\n",
      "8.25\t8.25\t13.5\t13.5\t0\t\n",
      "8.25\t8.25\t13.5\t13.5\t0\t\n",
      "0\t0\t0\t0\t0\t\n",
      "\n",
      "\n",
      "🔧 conv2d_backwards_bias_wr_sigma\n",
      "Grad Bias shape: [1, 1, 1, 1]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "2028\t\n",
      "\n",
      "\n",
      "🔧 relu_backwards\n",
      "Grad ReLU shape: [1, 1, 5, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "12\t21\t27\t33\t24\t\n",
      "33\t54\t63\t72\t51\t\n",
      "63\t99\t108\t117\t81\t\n",
      "93\t144\t153\t162\t111\t\n",
      "72\t111\t117\t123\t84\t\n",
      "\n",
      "\n",
      "🔧 bias_backwards\n",
      "Bias Backward shape: [1, 1, 1, 5]\n",
      "\n",
      "=== N=0, C=0 ===\n",
      "273\t429\t468\t507\t351\t\n",
      "\n",
      "\n",
      "\n",
      "✅ All tests complete!\n"
     ]
    }
   ],
   "source": [
    "data = np.arange(25, dtype=np.float32).reshape(1, 1, 5, 5)\n",
    "input_tensor = ibatensor.Tensor(data, 1)\n",
    "print_tensor_info(\"Input Tensor\", input_tensor)\n",
    "\n",
    "print(\"\\n Testing softmax\")\n",
    "softmax_out = input_tensor.softmax()\n",
    "print_tensor_info(\"Softmax Output\", softmax_out)\n",
    "\n",
    "# Create a 1x1x3x3 kernel (out_channels=1, in_channels=1, 3x3)\n",
    "kernel_data = np.ones((1, 1, 3, 3), dtype=np.float32)\n",
    "kernel_tensor = ibatensor.Tensor(kernel_data, 1)\n",
    "print_tensor_info(\"Kernel\", kernel_tensor)\n",
    "\n",
    "print(\"\\n🧪 Testing conv2d\")\n",
    "conv_output = input_tensor.conv2d(kernel_tensor, padding=1, stride=1)\n",
    "print_tensor_info(\"Conv2D Output\", conv_output)\n",
    "\n",
    "print(\"\\n🧪 Testing ReLU\")\n",
    "relu_out = conv_output.relu()\n",
    "print_tensor_info(\"ReLU Output\", relu_out)\n",
    "\n",
    "print(\"\\n🧪 Testing avg_pool\")\n",
    "avg_pooled = conv_output.avg_pool(K=2, padding=0, stride=2)\n",
    "print_tensor_info(\"Avg Pool Output\", avg_pooled)\n",
    "\n",
    "print(\"\\n🧪 Testing max_pool\")\n",
    "max_pool_result = conv_output.max_pool(K=2, padding=0, stride=2)\n",
    "print_tensor_info(\"max_pool\", max_pool_result.output)\n",
    "\n",
    "print(\"\\n🔁 Testing backprop functions\")\n",
    "\n",
    "# Use conv_output as sigma\n",
    "sigma = conv_output\n",
    "\n",
    "print(\"🔧 conv2d_backward_wr_kernel\")\n",
    "grad_kernel = ibatensor.conv2d_backward_wr_kernel(input_tensor, sigma, kernel_tensor, padding=1, stride=1)\n",
    "print_tensor_info(\"Grad Kernel\", grad_kernel)\n",
    "\n",
    "print(\"🔧 conv2d_backward_wr_input\")\n",
    "grad_input = ibatensor.conv2d_backward_wr_input(input_tensor, sigma, kernel_tensor, padding=1, stride=1)\n",
    "print_tensor_info(\"Grad Input\", grad_input)\n",
    "\n",
    "print(\"🔧 max_pool_backward_wr_input\")\n",
    "grad_mp = ibatensor.max_pool_backward_wr_input(conv_output, sigma, max_pool_result.max_inds_ptr, K=2, padding=0, stride=2)\n",
    "print_tensor_info(\"Grad Max Pool\", grad_mp)\n",
    "\n",
    "print(\"🔧 avg_pool_backward_wr_input\")\n",
    "grad_avg = ibatensor.avg_pool_backward_wr_input(conv_output, sigma, K=2, padding=0, stride=2)\n",
    "print_tensor_info(\"Grad Avg Pool\", grad_avg)\n",
    "\n",
    "print(\"🔧 conv2d_backwards_bias_wr_sigma\")\n",
    "grad_bias = ibatensor.conv2d_backwards_bias_wr_sigma(sigma)\n",
    "print_tensor_info(\"Grad Bias\", grad_bias)\n",
    "\n",
    "print(\"🔧 relu_backwards\")\n",
    "grad_relu = ibatensor.relu_backwards(sigma, conv_output)\n",
    "print_tensor_info(\"Grad ReLU\", grad_relu)\n",
    "\n",
    "print(\"🔧 bias_backwards\")\n",
    "grad_b = ibatensor.bias_backwards(sigma)\n",
    "print_tensor_info(\"Bias Backward\", grad_b)\n",
    "\n",
    "print(\"\\n✅ All tests complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af261f5e-414f-496c-8240-d0406c6b9029",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (input_tensor @ input_tensor.mat_transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a627b423-827f-4623-9ff4-7bc185f6672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1, 1,1, 1)  # or whatever shape you want\n",
    "array = np.full(shape, 0.1, dtype=np.float32)\n",
    "\n",
    "# Initialize the tensor on GPU (1) or CPU (0)\n",
    "tensor = ibatensor.Tensor(array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d546b5-767e-4830-a43a-f6b370e3c0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "nan\tnan\tnan\tnan\tnan\t\n",
      "nan\tnan\tnan\tnan\tnan\t\n",
      "nan\tnan\tnan\tnan\tnan\t\n",
      "nan\tnan\tnan\tnan\tnan\t\n",
      "nan\tnan\tnan\tnan\tnan\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((X.elem_wise_mult(learning_rate)).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b4bc2ae-0672-4573-8baf-5f03df285059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "30\t80\t130\t180\t230\t\n",
      "80\t255\t430\t605\t780\t\n",
      "130\t430\t730\t1030\t1330\t\n",
      "180\t605\t1030\t1455\t1880\t\n",
      "230\t780\t1330\t1880\t2430\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70beb874-d9bc-45bb-9d95-b177c35d71c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "0.1\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tensor.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf12894d-062d-4cd9-a837-3b697eddf12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "3\t8\t13\t18\t23\t\n",
      "8\t25.5\t43\t60.5\t78\t\n",
      "13\t43\t73\t103\t133\t\n",
      "18\t60.5\t103\t145.5\t188\t\n",
      "23\t78\t133\t188\t243\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((X.elem_wise_mult(tensor)).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98757727-4bf3-4a7a-8943-6cdf47e411f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t\n",
      "0\t0\t0\t0\t0\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X.elem_wise_sub(X).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "81d46fbf-06e6-4337-8294-25619331a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = 1\n",
    "class Linear:\n",
    "    def __init__(self, indim : int, outdim : int):\n",
    "        weights_initializer = np.random.rand(outdim, indim)\n",
    "        bias_initializer = np.random.rand(outdim)\n",
    "\n",
    "        weights_initializer.resize((1,1,outdim, indim))\n",
    "        self.weights = ibatensor.Tensor(weights_initializer, CUDA)\n",
    "\n",
    "        bias_initializer.resize((1,1,1,outdim))\n",
    "        self.bias = ibatensor.Tensor(bias_initializer, CUDA)\n",
    "\n",
    "        self.prev_update_weights = None\n",
    "        self.prev_update_bias = None\n",
    "        self.prev_input = None\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.prev_input = X\n",
    "\n",
    "        return (self.weights @ X).elem_wise_add(self.bias)\n",
    "\n",
    "    def backward(self, sigma):\n",
    "        grad_w = sigma @ self.prev_input.mat_transpose()\n",
    "        grad_b = ibatensor.bias_backwards(sigma)\n",
    "\n",
    "        if(self.prev_update_weights == None):\n",
    "            update_weights = grad_w.elem_wise_mult(learning_rate).elem_wise_mult(tensor_neg_one)\n",
    "            self.weights = self.weights.elem_wise_sub(update_weights)\n",
    "            update_bias = grad_b.elem_wise_mult(learning_rate).elem_wise_mult(learning_rate)\n",
    "            self.bias = self.bias.elem_wise_sub(update_bias)\n",
    "\n",
    "            self.prev_update_weights = update_weights\n",
    "            self.prev_update_bias = update_bias\n",
    "        else:\n",
    "            update_weights = self.prev_update_weights.elem_wise_mult(mew).elem_wise_sub(grad_w.elem_wise_mult(learning_rate).elem_wise_mult(tensor_neg_one))\n",
    "            self.weights = self.weights.elem_wise_sub(update_weights)\n",
    "            update_bias = self.prev_update_weights.elem_wise_mult(mew).elem_wise_sub(grad_b.elem_wise_mult(learning_rate).elem_wise_mult(learning_rate))\n",
    "            self.bias = self.bias.elem_wise_sub(update_bias)\n",
    "\n",
    "            self.prev_update_weights = update_weights\n",
    "            self.prev_update_bias = update_bias\n",
    "\n",
    "        return self.weights.mat_transpose() @ sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eebd6952-0b7e-4b62-b6e7-12562b38c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = Linear(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a8768a3-85d1-4b40-b0f8-e610aa34348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_np = ibatensor.Tensor(np.random.rand(5, 2).astype(np.float32).reshape((1, 1, 5, 2)), CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "360f8a24-dde7-4aef-a51c-a59dbfca9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = linear.forward(input_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2395f7c-bd12-4bc8-bb5e-0da6b001f155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "0.902448\t1.45945\t\n",
      "0.63938\t1.03205\t\n",
      "1.38612\t1.42005\t\n",
      "0.780132\t1.27718\t\n",
      "1.39401\t1.17011\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "601b81ed-9460-448a-8e6b-4dc0a440baa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_np = np.random.rand(3, 2).astype(np.float32).reshape((1, 1, 3, 2))\n",
    "sigma_tensor = ibatensor.Tensor(sigma_np, CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b969ffd9-dac4-4fc7-83c5-1529dfe8403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = ibatensor.Tensor(np.full((1,1,1,1), 0.1, dtype=np.float32), 1)\n",
    "mew = ibatensor.Tensor(np.full((1,1,1,1), 0.9, dtype=np.float32), 1)\n",
    "tensor_neg_one = ibatensor.Tensor(np.full((1,1,1,1), -1, dtype=np.float32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "626cda55-8ee1-4ab3-aa91-7a11687513a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_input = linear.backward(sigma_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8eb88958-cc15-4d6e-a1a2-f929c8c11e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "1.57468\t1.42877\t\n",
      "1.26321\t1.36643\t\n",
      "1.42836\t1.4988\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(grad_input.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3afff09f-bf73-4863-ba73-bca6ad6dc889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "0.647286\t0.425714\t0.917799\t\n",
      "0.444568\t0.0711111\t0.297371\t\n",
      "0.761321\t0.624283\t0.732794\t\n",
      "0.174874\t0.546276\t0.693221\t\n",
      "0.761664\t0.560076\t0.15588\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(linear.weights.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "82342d70-71f2-4238-872d-c5fd0fe4bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.prev_output = None\n",
    "        return\n",
    "\n",
    "    def forward(self, X):\n",
    "        out = X.relu()\n",
    "        self.prev_output = out\n",
    "        return out\n",
    "        \n",
    "\n",
    "    def backward(self, sigma):\n",
    "        return ibatensor.relu_backwards(sigma, self.prev_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "edd04d40-3527-4743-b38c-38967705ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_relu = ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b077a56c-4250-477f-8970-6dfbb3721d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_out = out.elem_wise_add(tensor_neg_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3beb87a8-930a-4d7b-a67a-bb6dab92654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "-0.0975517\t0.459453\t\n",
      "-0.36062\t0.0320485\t\n",
      "0.386116\t0.420053\t\n",
      "-0.219868\t0.277184\t\n",
      "0.394013\t0.170113\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(new_out.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "54c94664-de17-4b6f-bdab-20699d5f6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "activated_out = linear_relu.forward(new_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9ac4bb78-6e3d-4642-93e5-8127861d3c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "0\t0.459453\t\n",
      "0\t0.0320485\t\n",
      "0.386116\t0.420053\t\n",
      "0\t0.277184\t\n",
      "0.394013\t0.170113\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(activated_out.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "941f8357-a498-475f-97cd-a7fbbc82f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_grad = linear_relu.backward(activated_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f4c17e2e-fb0d-4354-9b47-a7cf629a9245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "0\t0.459453\t\n",
      "0\t0.0320485\t\n",
      "0.386116\t0.420053\t\n",
      "0\t0.277184\t\n",
      "0.394013\t0.170113\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(relu_grad.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c1fa4c91-f80e-4d51-90a5-818d56ea0d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== N=0, C=0 ===\n",
      "0.387116\t0.612884\t\n",
      "0.491989\t0.508011\t\n",
      "0.491517\t0.508483\t\n",
      "0.431144\t0.568856\t\n",
      "0.555742\t0.444258\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(relu_grad.softmax().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348a81b-a8e0-474d-b9b9-657ace1bf6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
